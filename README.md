
## Overview

Eyelid malignancies present a diagnostic challenge in computational pathology due to their complex subtypes and the absence of dedicated representation in current pathology foundation models. We propose ELSiP (Eyelid malignancies diagnosis with Slide and Patch integration), a framework that integrates slide-level and patch-level features to enhance model performance on private datasets. To further calibrate predictions, we incorporate clinical variables including age and sex, capitalizing on their strong epidemiological association with eyelid cancer incidence. Our framework addresses the dual diagnostic challenges of distinguishing benign from malignant lesions and performing fine-grained classification across nine distinct subtypes. Using a multicenter dataset comprising 1,430 whole-slide images (WSIs) from 1,054 patients, we demonstrate that ELSiP achieves accurate discrimination of eyelid tumors and their subcategories. From a clinical perspective, the heatmaps generated by ELSiP successfully highlight key regions consistent with pathological expertise. Moreover, in comparative experiments with pathologists, the framework achieved diagnostic accuracy that was comparable to, or exceeded, that of human experts, underscoring its potential as a reliable auxiliary tool for ophthalmic pathology.

![ELSiP Framework](fig/main.jpeg)

## Installation

### Setup

1. Clone the repository:
   ```bash
   git clone https://github.com/Zzihao123/ELSiP
   cd ELSiP
   ```

2. Create and activate the conda environment, and install dependencies:
   ```bash
   conda env create -f environment.yml
   conda activate ELSiP
   ```

<!-- ### Install Time
- Fresh installation with conda environment creation: ~10-15 minutes on a normal desktop computer
- Installation of additional dependencies: ~5 minutes
- Download of pretrained models (optional): ~10-20 minutes depending on internet speed -->

## Instructions for Use

### Data Preparation

Due to the large size of WSIs, patch-level features must be extracted first. Use established pipelines like [CLAM](https://github.com/mahmoodlab/CLAM) or [TRIDENT](https://github.com/mahmoodlab/TRIDENT). Extraction is computationally intensive. Place extracted features (e.g., `.h5` files) inside `features/` for each dataset as shown below:
```
Dataset/
├── Dataset1/
│   └── features/
│       ├── 1.h5
│       ├── 2.h5
│       └── ...
├── Dataset2/
│   └── features/
│       ├── 1.h5
│       ├── 2.h5
│       └── ...
└── ...
```

### Running on Your Data

#### Generate Data Splits

Create splits for your dataset:
```bash
cd src
bash sh_tools/1_create_splits.sh
```

#### Train the ELSiP Model

Train and evaluate the model:
```bash
bash sh_tools/2_train_multimodal.sh
```

#### Evaluate the ELSiP Model

Evaluate the performance of the trained model:
```bash
bash sh_tools/3_eval_multimodal.sh
```
Refer to our paper for detailed results.

## License

This project is licensed under the [Apache-2.0 license](LICENSE).

## Acknowledgments

This project was built on the top of amazing works, including [CLAM](https://github.com/mahmoodlab/CLAM), [CONCH](https://github.com/mahmoodlab/CONCH), [QuiltNet](https://huggingface.co/wisdomik/QuiltNet-B-32), [PathGen-CLIP](https://huggingface.co/jamessyx/PathGen-CLIP), and [PreservedSiteCV](https://github.com/fmhoward/PreservedSiteCV). We thank the authors for their great works.